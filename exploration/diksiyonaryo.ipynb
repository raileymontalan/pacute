{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b0176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import string\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f677b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>etymology</th>\n",
       "      <th>word_sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>nyuk</td>\n",
       "      <td>png</td>\n",
       "      <td>[ Mag ]</td>\n",
       "      <td>niyóg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>nyuknyúk</td>\n",
       "      <td>png</td>\n",
       "      <td>[ Tau ]</td>\n",
       "      <td>kadalisayan o kapinuhan ng hábi ng tela.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>nyur</td>\n",
       "      <td>png</td>\n",
       "      <td>[ Mag ]</td>\n",
       "      <td>niyóg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>nyuy</td>\n",
       "      <td>png</td>\n",
       "      <td>[ Iva ]</td>\n",
       "      <td>niyóg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>Nyx</td>\n",
       "      <td>png</td>\n",
       "      <td>[ Gri ]</td>\n",
       "      <td>babaeng personipikasyon ng gabí ; anak ni Chaos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word part_of_speech etymology  \\\n",
       "1166      nyuk            png   [ Mag ]   \n",
       "1167  nyuknyúk            png   [ Tau ]   \n",
       "1168      nyur            png   [ Mag ]   \n",
       "1169      nyuy            png   [ Iva ]   \n",
       "1170       Nyx            png   [ Gri ]   \n",
       "\n",
       "                                            word_sense  \n",
       "1166                                            niyóg.  \n",
       "1167          kadalisayan o kapinuhan ng hábi ng tela.  \n",
       "1168                                            niyóg.  \n",
       "1169                                            niyóg.  \n",
       "1170  babaeng personipikasyon ng gabí ; anak ni Chaos.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_files = glob.glob(\"/Users/raileymontalan/Documents/railey-aisg/pacute/output_folder/*.jsonl\")\n",
    "df1 = pd.read_json(jsonl_files[25], lines=True)\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05635dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/itudidyay/Tagalog-Word-Syllabization-Python/blob/main/tglSyllabification.py\n",
    "\n",
    "vowels = set(\"AEIOUaeiouÀÁÂÈÉÊÌÍÎÒÓÔÙÚÛàáâèéêìíîòóôùúû\")\n",
    "letter_pairs = set([\"bl\", \"br\", \"dr\", \"pl\", \"tr\"])\n",
    "\n",
    "def haveVowel(word):\n",
    "    for let in word:\n",
    "        if let in vowels:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def sliceValueInList(listSlice, valueSlice, indexSlice):\n",
    "    result = listSlice[:]\n",
    "    result.insert(valueSlice + 1, result[valueSlice][indexSlice:])\n",
    "    result[valueSlice] = result[valueSlice][:indexSlice]\n",
    "    return result\n",
    "\n",
    "\n",
    "def mergeValueInList(listMerge, fromMerge, toMerge):\n",
    "    result = listMerge[:]\n",
    "    result[fromMerge : toMerge + 1] = [\"\".join(result[fromMerge : toMerge + 1])]\n",
    "    return result\n",
    "\n",
    "\n",
    "def syllabify(wordToSyllabify):\n",
    "    word = wordToSyllabify\n",
    "\n",
    "    # Break down word to constants and vowels. Ex: maglakad = ['m','a','gl','a','k','a','d']\n",
    "\n",
    "    nextNg = False\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            word = word.replace(letter, f\" {letter} \")\n",
    "        elif letter == \"-\":\n",
    "            word = word.replace(letter, f\" - \")\n",
    "    word = word.replace(\"ng\", \"ŋ\").replace(\"NG\", \"Ŋ\")  # ng is temporarily replaced with ŋ so that it counts as one letter, hope its not some bullshit like 'Ng' or \"nG\"\n",
    "    word = word.replace(\"'\", \"\") # dont like apostrophes\n",
    "    word = word.split()\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    for index, group in enumerate(word[:]):\n",
    "        index += offset\n",
    "        if index == 0 or index == len(word[:]) - 1 or word[index-1] == '-': # ignore at start or beginning of word, or if prev group was a hyphen\n",
    "            continue\n",
    "        elif len(group) == 2 and word: # if two letters, then split in half\n",
    "            word = sliceValueInList(word[:], index, 1)\n",
    "            offset += 1\n",
    "        elif len(group) == 3:\n",
    "            if (\n",
    "                any((group[0].lower() == \"n\", group[0].lower() == \"m\"))\n",
    "                and group[1:3].lower() in letter_pairs\n",
    "            ):  # if three letters and 1st letter is n/m and 2nd-3rd letter is bl, br, dr, pl, or tr, split n/m from letter pairs\n",
    "                word = sliceValueInList(word[:], index, 1)\n",
    "                offset += 1\n",
    "            else: # if three letters and none of above rules apply, split first two letters from last letter\n",
    "                word = sliceValueInList(word[:], index, 2)\n",
    "                offset += 1\n",
    "        elif len(group) > 3: # if four or more letters, detach first two letters\n",
    "            word = sliceValueInList(word[:], index, 2)\n",
    "            offset += 1\n",
    "\n",
    "    # Join vowels with the constants that precede them\n",
    "\n",
    "    joinWord = word[:]\n",
    "    offset = 0\n",
    "    for index, group in enumerate(joinWord):\n",
    "        if (\n",
    "            group[-1] in vowels\n",
    "            and joinWord[index - 1] not in vowels\n",
    "            and joinWord[index - 1] != \"-\"\n",
    "            and index != 0\n",
    "        ):\n",
    "            word = mergeValueInList(word, index - 1 - offset, index - offset)\n",
    "            offset += 1\n",
    "\n",
    "    # Join vowels with the constants that follow them\n",
    "\n",
    "    joinWord = word[:]\n",
    "    offset = 0\n",
    "    for index, group in enumerate(joinWord):\n",
    "        if index != len(joinWord) - 1:\n",
    "            if (\n",
    "                group[-1] in vowels\n",
    "                and not haveVowel(joinWord[index + 1])\n",
    "                and joinWord[index + 1] != \"-\"\n",
    "            ):\n",
    "                word = mergeValueInList(word, index - offset, index + 1 - offset)\n",
    "                offset += 1\n",
    "    for i in range(len(word)):\n",
    "        word[i] = word[i].replace(\"ŋ\", \"ng\").replace(\"Ŋ\", \"NG\")  # ŋ returns to ng\n",
    "\n",
    "    while \"-\" in word: # bye bye hyphen\n",
    "        word.remove(\"-\")\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d9899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accented_vowels = set(\"ÀÁÂÈÉÊÌÍÎÒÓÔÙÚÛàáâèéêìíîòóôùúû\")\n",
    "mabilis = set(\"ÁÉÍÓÚáéíóú\")\n",
    "malumi = set(\"ÀÈÌÒÙàèìòù\")\n",
    "maragsa = set(\"ÂÊÎÔÛâêîôû\")\n",
    "\n",
    "\n",
    "def is_filipino(etymology):\n",
    "    return any(tag in etymology for tag in [\"Tag\", \"ST\", \"none\"])\n",
    "\n",
    "def is_single_word(word):\n",
    "    return len(word.split()) == 1\n",
    "\n",
    "def has_one_accented_syllable(word):\n",
    "    syllables = syllabify(word)\n",
    "    count = sum(1 for syllable in syllables if any(char in accented_vowels for char in syllable))\n",
    "    return count == 1\n",
    "\n",
    "def not_circumfixed_with_dash(word):\n",
    "    return not (word.startswith('-') or word.endswith('-'))\n",
    "\n",
    "def normalize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Strip whitespace\n",
    "        text = text.strip()\n",
    "        # Remove punctuation except dashes (-)\n",
    "        punctuation = string.punctuation.replace('-', '')\n",
    "        text = ''.join(c for c in text if c not in punctuation)\n",
    "        # Remove accents\n",
    "        text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    return text\n",
    "\n",
    "def find_accented_syllable(syllables):\n",
    "    for i, syllable in enumerate(syllables):\n",
    "        if any(char in accented_vowels for char in syllable):\n",
    "            return syllable, i\n",
    "    return \"\", -1  # Return -1 if no accented syllable is found\n",
    "\n",
    "def find_last_syllable(syllables):\n",
    "    return syllables[-1], len(syllables) - 1\n",
    "\n",
    "def classify_last_syllable_pronunciation(last_syllable):\n",
    "    if any(char in mabilis for char in last_syllable):\n",
    "        return \"mabilis\"\n",
    "    elif any(char in malumi for char in last_syllable):\n",
    "        return \"malumi\"\n",
    "    elif any(char in maragsa for char in last_syllable):\n",
    "        return \"maragsa\"\n",
    "    else:\n",
    "        return \"malumay\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf72b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=df1.columns)\n",
    "for file in jsonl_files:\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    df_filtered = df[df['etymology'].apply(is_filipino)].copy()\n",
    "    df_filtered = df_filtered[df_filtered['word'].apply(is_single_word)].copy()\n",
    "    df_filtered = df_filtered[df_filtered['word'].apply(has_one_accented_syllable)].copy()\n",
    "    df_filtered = df_filtered[df_filtered['word'].apply(not_circumfixed_with_dash)].copy()\n",
    "    if df_filtered.empty:\n",
    "        continue\n",
    "    df_filtered['accented_syllable_list'] = df_filtered['word'].apply(syllabify)\n",
    "    df_filtered['accented_syllable'] = df_filtered['accented_syllable_list'].apply(lambda x: find_accented_syllable(x)[0])\n",
    "    df_filtered['accented_syllable_index'] = df_filtered['accented_syllable_list'].apply(lambda x: find_accented_syllable(x)[1])\n",
    "    df_filtered['accented_syllable_index'] = df_filtered['accented_syllable_index'].astype(pd.Int64Dtype())\n",
    "    df_filtered['last_syllable'] = df_filtered['accented_syllable_list'].apply(lambda x: find_last_syllable(x)[0])\n",
    "    df_filtered['last_syllable_index'] = df_filtered['accented_syllable_list'].apply(lambda x: find_last_syllable(x)[1])\n",
    "    df_filtered['last_syllable_index'] = df_filtered['last_syllable_index'].astype(pd.Int64Dtype())\n",
    "    df_filtered['last_syllable_pronunciation'] = df_filtered['last_syllable'].apply(classify_last_syllable_pronunciation)\n",
    "    df_filtered['normalized_word'] = df_filtered['word'].apply(normalize_text)\n",
    "    df_filtered['normalized_syllable_list'] = df_filtered['normalized_word'].apply(syllabify)\n",
    "    data = pd.concat([data, df_filtered], ignore_index=True)\n",
    "\n",
    "processed_data = data.sort_values(by='normalized_word').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b42317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_json(\"data/syllables.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba0e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diksiyonaryo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
